{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN node classification for AML detection\n",
    "### The main code for the GNN was referenced from, https://github.com/IBM/Pattern-GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path = 'data\\\\raw\\LI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "0  2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
      "1  2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
      "2  2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
      "3  2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
      "4  2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
      "\n",
      "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "0       3195403.00          US Dollar   3195403.00        US Dollar   \n",
      "1          1858.96          US Dollar      1858.96        US Dollar   \n",
      "2        592571.00          US Dollar    592571.00        US Dollar   \n",
      "3            12.32          US Dollar        12.32        US Dollar   \n",
      "4          2941.56          US Dollar      2941.56        US Dollar   \n",
      "\n",
      "  Payment Format  Is Laundering  \n",
      "0   Reinvestment              0  \n",
      "1   Reinvestment              0  \n",
      "2         Cheque              0  \n",
      "3   Reinvestment              0  \n",
      "4   Reinvestment              0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp              object\n",
      "From Bank               int64\n",
      "Account                object\n",
      "To Bank                 int64\n",
      "Account.1              object\n",
      "Amount Received       float64\n",
      "Receiving Currency     object\n",
      "Amount Paid           float64\n",
      "Payment Currency       object\n",
      "Payment Format         object\n",
      "Is Laundering           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset would be turned into a ndoe classification problem \n",
    "\n",
    "Accounts as nodes and transactions as edges. Objects column would needed to be encoded using LabelEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp             0\n",
      "From Bank             0\n",
      "Account               0\n",
      "To Bank               0\n",
      "Account.1             0\n",
      "Amount Received       0\n",
      "Receiving Currency    0\n",
      "Amount Paid           0\n",
      "Payment Currency      0\n",
      "Payment Format        0\n",
      "Is Laundering         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for imbalances in transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Received equals to Amount Paid:\n",
      "False\n",
      "Receiving Currency equals to Payment Currency:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Amount Received equals to Amount Paid:')\n",
    "print(df['Amount Received'].equals(df['Amount Paid']))\n",
    "print('Receiving Currency equals to Payment Currency:')\n",
    "print(df['Receiving Currency'].equals(df['Payment Currency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seens involved the transcations between different currency, let's print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98858 rows x 11 columns]\n",
      "---------------------------------------------------------------------------\n",
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98876 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
    "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
    "print(not_equal1)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(not_equal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount received and paid are not the same meaning that there might be transactiuon fees involved. cannot remove and use only 1 amount column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df['Receiving Currency'].unique()))\n",
    "print(sorted(df['Payment Currency'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data preprocessing, these transformations were done:  \n",
    "1. Transform the Timestamp with min max normalization.  \n",
    "2. Create unique ID for each account by adding bank code with account number.  \n",
    "3. Create receiving_df with the information of receiving accounts, received amount and currency\n",
    "4. Create paying_df with the information of payer accounts, paid amount and currency\n",
    "5. Create a list of currency used among all transactions\n",
    "6. Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_label_encoder(df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "def preprocess(df):\n",
    "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look of processed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  From Bank      Account  To Bank        Account.1  \\\n",
      "3408783   0.266147          0  0_800060CE0    11314  11314_800990320   \n",
      "3986981   0.318925          0  0_800060CE0    11314  11314_800990320   \n",
      "4804475   0.393400          0  0_800060CE0    11314  11314_800990320   \n",
      "4804474   0.394151          0  0_800060CE0    11314  11314_800990320   \n",
      "6690464   0.547730          0  0_800060CE0     1390   1390_800E49870   \n",
      "\n",
      "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
      "3408783          8081.58                   4      8081.58                 4   \n",
      "3986981         47468.31                   4     47468.31                 4   \n",
      "4804475          8081.58                   4      8081.58                 4   \n",
      "4804474         47468.31                   4     47468.31                 4   \n",
      "6690464           787.72                   4       787.72                 4   \n",
      "\n",
      "         Payment Format  Is Laundering  \n",
      "3408783               4              0  \n",
      "3986981               3              0  \n",
      "4804475               4              0  \n",
      "4804474               3              0  \n",
      "6690464               3              0  \n"
     ]
    }
   ],
   "source": [
    "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paying df and receiving df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Account  Amount Received  Receiving Currency\n",
      "3408783  11314_800990320          8081.58                   4\n",
      "3986981  11314_800990320         47468.31                   4\n",
      "4804475  11314_800990320          8081.58                   4\n",
      "4804474  11314_800990320         47468.31                   4\n",
      "6690464   1390_800E49870           787.72                   4\n",
      "             Account  Amount Paid  Payment Currency\n",
      "3408783  0_800060CE0      8081.58                 4\n",
      "3986981  0_800060CE0     47468.31                 4\n",
      "4804475  0_800060CE0      8081.58                 4\n",
      "4804474  0_800060CE0     47468.31                 4\n",
      "6690464  0_800060CE0       787.72                 4\n"
     ]
    }
   ],
   "source": [
    "print(receiving_df.head())\n",
    "print(paying_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currency_ls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "print(currency_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the node of the graph, the unique accounts for payer and receiver would be extracted, this would include its id and bank code, and if it is laundering. both payer and receiver for the laundering trasaction would be marked as laundering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_account(df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look of the account list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Account  Bank  Is Laundering\n",
      "0  0_800060CE0     0              0\n",
      "1  0_800061260     0              0\n",
      "2  0_800062D90     0              0\n",
      "3  0_800062F80     0              0\n",
      "4  0_800064980     0              0\n"
     ]
    }
   ],
   "source": [
    "accounts = get_all_account(df)\n",
    "print(accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node features\n",
    "For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
    "    for i in currency_ls:\n",
    "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "    accounts = accounts.fillna(0)\n",
    "    return accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = df_label_encoder(node_df,['Bank'])\n",
    "#         node_df = torch.from_numpy(node_df.values).to(torch.float)  # comment for visualization\n",
    "        return node_df, node_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
      "0     0         0.0         0.0         0.0         0.0         0.0   \n",
      "1     0         0.0         0.0         0.0         0.0         0.0   \n",
      "2     0         0.0         0.0         0.0         0.0         0.0   \n",
      "3     0         0.0         0.0         0.0         0.0         0.0   \n",
      "4     0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "\n",
      "   avg paid 11    avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
      "0          0.0  307628.336486          0.0          0.0             0.0   \n",
      "1          0.0    1858.960000          0.0          0.0             0.0   \n",
      "2          0.0  307628.336486          0.0          0.0             0.0   \n",
      "3          0.0      12.320000          0.0          0.0             0.0   \n",
      "4          0.0     175.632857          0.0          0.0             0.0   \n",
      "\n",
      "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
      "0             0.0              0.0              0.0     86494.373514   \n",
      "1             0.0              0.0              0.0      1858.960000   \n",
      "2             0.0              0.0              0.0    592571.000000   \n",
      "3             0.0              0.0              0.0        12.320000   \n",
      "4             0.0              0.0              0.0       206.122143   \n",
      "\n",
      "   avg received 13  avg received 14  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "print(node_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features\n",
    "What is edge features?\n",
    "\n",
    "Edge features are the attributes of the edges in the graph. In the context of the AML detection, the edge features are the attributes of the transactions between the accounts. To be simple its like the connection between the nodes.\n",
    "\n",
    "For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]\n",
    "\n",
    "For edge attributes, \n",
    "\n",
    "'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_df(accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "#         edge_attr = torch.from_numpy(df.values).to(torch.float)  # comment for visualization\n",
    "\n",
    "        edge_attr = df  # for visualization\n",
    "        return edge_attr, edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_attr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
      "3408783   0.266147          8081.58                   4      8081.58   \n",
      "3986981   0.318925         47468.31                   4     47468.31   \n",
      "4804475   0.393400          8081.58                   4      8081.58   \n",
      "4804474   0.394151         47468.31                   4     47468.31   \n",
      "6690464   0.547730           787.72                   4       787.72   \n",
      "\n",
      "         Payment Currency  Payment Format  \n",
      "3408783                 4               4  \n",
      "3986981                 4               3  \n",
      "4804475                 4               4  \n",
      "4804474                 4               3  \n",
      "6690464                 4               3  \n"
     ]
    }
   ],
   "source": [
    "edge_attr, edge_index = get_edge_df(accounts, df)\n",
    "print(edge_attr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,      0,      0,  ..., 681281, 681282, 681282],\n",
      "        [ 22343,  22343,  22343,  ..., 681281, 681282, 681282]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "Graph Attention Networks was used for the model.\n",
    "This GAT class defines a two-layer Graph Attention Network for processing graph data. It uses attention mechanisms to focus on important parts of the graph and applies dropout for regularization. The network architecture is designed to transform node features through two GAT layers followed by a linear layer and a sigmoid activation to produce the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv, Linear\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
    "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = self.lin(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG InMemoryDataset\n",
    "The Dataset would be built using the functions made above.\n",
    "\n",
    "The AMLtoGraph class is designed to process transaction data from a CSV file and convert it into a graph format suitable for graph neural network (GNN) training. It inherits from InMemoryDataset, which is a part of the PyTorch Geometric library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMLtoGraph(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root: str, edge_window_size: int = 10,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        self.edge_window_size = edge_window_size\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'HI-Small_Trans.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self._data.edge_index.max().item() + 1\n",
    "\n",
    "    def df_label_encoder(self, df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls\n",
    "\n",
    "    def get_all_account(self, df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    \n",
    "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "        accounts = accounts.fillna(0)\n",
    "        return accounts\n",
    "\n",
    "    def get_edge_df(self, accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
    "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "        return node_df, node_label\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
    "        accounts = self.get_all_account(df)\n",
    "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
    "\n",
    "        data = Data(x=node_attr,\n",
    "                    edge_index=edge_index,\n",
    "                    y=node_label,\n",
    "                    edge_attr=edge_attr\n",
    "                    )\n",
    "        \n",
    "        data_list = [data] \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a graph neural network (GNN) using PyTorch and PyTorch Geometric, specifically focusing on a Graph Attention Network (GAT). It processes transaction data, splits it into training and validation sets, and trains the model to detect suspicious transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3539.0887\n",
      "accuracy: 0.9687609162133839\n",
      "Epoch: 001, Loss: 2196.2791\n",
      "accuracy: 0.9699783920275065\n",
      "Epoch: 002, Loss: 2104.6358\n",
      "accuracy: 0.9699872700496718\n",
      "Epoch: 003, Loss: 2004.3377\n",
      "accuracy: 0.9702978697917707\n",
      "Epoch: 004, Loss: 1938.8116\n",
      "accuracy: 0.9699355012495697\n",
      "Epoch: 005, Loss: 1893.9508\n",
      "accuracy: 0.9701303430421357\n",
      "Epoch: 006, Loss: 1842.7416\n",
      "accuracy: 0.9706239172437207\n",
      "Epoch: 007, Loss: 1799.4301\n",
      "accuracy: 0.9707260595958739\n",
      "Epoch: 008, Loss: 1750.1756\n",
      "accuracy: 0.9707752030816518\n",
      "Epoch: 009, Loss: 1760.9437\n",
      "accuracy: 0.9708991673360241\n",
      "Epoch: 010, Loss: 1720.9987\n",
      "accuracy: 0.9709595959595959\n",
      "Epoch: 011, Loss: 1692.9881\n",
      "accuracy: 0.9711886491964673\n",
      "Epoch: 012, Loss: 1685.2074\n",
      "accuracy: 0.9712663764179581\n",
      "Epoch: 013, Loss: 1642.8474\n",
      "accuracy: 0.9710630353613002\n",
      "Epoch: 014, Loss: 1635.3046\n",
      "accuracy: 0.9709446845893522\n",
      "Epoch: 015, Loss: 1619.7822\n",
      "accuracy: 0.9709762401333187\n",
      "Epoch: 016, Loss: 1597.0071\n",
      "accuracy: 0.9713059319707519\n",
      "Epoch: 017, Loss: 1578.0267\n",
      "accuracy: 0.9713006990215693\n",
      "Epoch: 018, Loss: 1560.3231\n",
      "accuracy: 0.9713134601079365\n",
      "Epoch: 019, Loss: 1559.0768\n",
      "accuracy: 0.9714670725925186\n",
      "Epoch: 020, Loss: 1542.5002\n",
      "accuracy: 0.9714891705759058\n",
      "Epoch: 021, Loss: 1549.6613\n",
      "accuracy: 0.9715666066090046\n",
      "Epoch: 022, Loss: 1546.0234\n",
      "accuracy: 0.9715998123621411\n",
      "Epoch: 023, Loss: 1534.2025\n",
      "accuracy: 0.9715980227355484\n",
      "Epoch: 024, Loss: 1539.1275\n",
      "accuracy: 0.9725821586870582\n",
      "Epoch: 025, Loss: 1539.1689\n",
      "accuracy: 0.9722638156843955\n",
      "Epoch: 026, Loss: 1519.8094\n",
      "accuracy: 0.9723559791422369\n",
      "Epoch: 027, Loss: 1515.1303\n",
      "accuracy: 0.9722725525723385\n",
      "Epoch: 028, Loss: 1517.2551\n",
      "accuracy: 0.9724050127315392\n",
      "Epoch: 029, Loss: 1509.2458\n",
      "accuracy: 0.9723268870867124\n",
      "Epoch: 030, Loss: 1499.4513\n",
      "accuracy: 0.9723240514915287\n",
      "Epoch: 031, Loss: 1514.9082\n",
      "accuracy: 0.9728646576764521\n",
      "Epoch: 032, Loss: 1507.1318\n",
      "accuracy: 0.9728140999411172\n",
      "Epoch: 033, Loss: 1519.8932\n",
      "accuracy: 0.9728620842837676\n",
      "Epoch: 034, Loss: 1522.4801\n",
      "accuracy: 0.9729360156105741\n",
      "Epoch: 035, Loss: 1506.5564\n",
      "accuracy: 0.9728270900991235\n",
      "Epoch: 036, Loss: 1501.6635\n",
      "accuracy: 0.9727593845416991\n",
      "Epoch: 037, Loss: 1509.5839\n",
      "accuracy: 0.972738383258923\n",
      "Epoch: 038, Loss: 1500.0132\n",
      "accuracy: 0.9727903369789095\n",
      "Epoch: 039, Loss: 1488.8537\n",
      "accuracy: 0.9728990663626066\n",
      "Epoch: 040, Loss: 1491.3896\n",
      "accuracy: 0.9727417399589929\n",
      "Epoch: 041, Loss: 1492.7210\n",
      "accuracy: 0.9729732426122872\n",
      "Epoch: 042, Loss: 1517.6061\n",
      "accuracy: 0.9729718943619112\n",
      "Epoch: 043, Loss: 1504.4292\n",
      "accuracy: 0.9729066129024209\n",
      "Epoch: 044, Loss: 1502.7131\n",
      "accuracy: 0.9728798000409098\n",
      "Epoch: 045, Loss: 1510.0747\n",
      "accuracy: 0.9731523182775942\n",
      "Epoch: 046, Loss: 1492.0993\n",
      "accuracy: 0.9729120201974844\n",
      "Epoch: 047, Loss: 1501.3054\n",
      "accuracy: 0.9728724546085377\n",
      "Epoch: 048, Loss: 1489.2593\n",
      "accuracy: 0.972921034241789\n",
      "Epoch: 049, Loss: 1509.9633\n",
      "accuracy: 0.9730077633863532\n",
      "Epoch: 050, Loss: 1489.6333\n",
      "accuracy: 0.9730296254891001\n",
      "Epoch: 051, Loss: 1488.6198\n",
      "accuracy: 0.9731688327244415\n",
      "Epoch: 052, Loss: 1490.6425\n",
      "accuracy: 0.9731124822780007\n",
      "Epoch: 053, Loss: 1489.2563\n",
      "accuracy: 0.9729998153406965\n",
      "Epoch: 054, Loss: 1507.5327\n",
      "accuracy: 0.9729218640854206\n",
      "Epoch: 055, Loss: 1495.0284\n",
      "accuracy: 0.9729633937530264\n",
      "Epoch: 056, Loss: 1466.0415\n",
      "accuracy: 0.9729716239486885\n",
      "Epoch: 057, Loss: 1469.6734\n",
      "accuracy: 0.9729049651763648\n",
      "Epoch: 058, Loss: 1492.3967\n",
      "accuracy: 0.9730249231137916\n",
      "Epoch: 059, Loss: 1477.9934\n",
      "accuracy: 0.9729817383494661\n",
      "Epoch: 060, Loss: 1482.8730\n",
      "accuracy: 0.9729899654203695\n",
      "Epoch: 061, Loss: 1476.3663\n",
      "accuracy: 0.9729280361092665\n",
      "Epoch: 062, Loss: 1471.0013\n",
      "accuracy: 0.9730529509513806\n",
      "Epoch: 063, Loss: 1478.9055\n",
      "accuracy: 0.9729949633859624\n",
      "Epoch: 064, Loss: 1482.9096\n",
      "accuracy: 0.9729491106078594\n",
      "Epoch: 065, Loss: 1469.6152\n",
      "accuracy: 0.9730375647991538\n",
      "Epoch: 066, Loss: 1475.4566\n",
      "accuracy: 0.9730241244825296\n",
      "Epoch: 067, Loss: 1465.3836\n",
      "accuracy: 0.9729539568560721\n",
      "Epoch: 068, Loss: 1473.5445\n",
      "accuracy: 0.972974051697042\n",
      "Epoch: 069, Loss: 1472.0893\n",
      "accuracy: 0.9729956331877729\n",
      "Epoch: 070, Loss: 1475.1246\n",
      "accuracy: 0.9729153667606759\n",
      "Epoch: 071, Loss: 1459.5513\n",
      "accuracy: 0.9728711190975342\n",
      "Epoch: 072, Loss: 1460.6320\n",
      "accuracy: 0.9729949715118921\n",
      "Epoch: 073, Loss: 1468.8335\n",
      "accuracy: 0.972855217846983\n",
      "Epoch: 074, Loss: 1454.9964\n",
      "accuracy: 0.972969600782564\n",
      "Epoch: 075, Loss: 1456.2246\n",
      "accuracy: 0.9729123129024374\n",
      "Epoch: 076, Loss: 1470.6503\n",
      "accuracy: 0.9729392505639736\n",
      "Epoch: 077, Loss: 1461.5379\n",
      "accuracy: 0.972963526974062\n",
      "Epoch: 078, Loss: 1449.8924\n",
      "accuracy: 0.9729333286767017\n",
      "Epoch: 079, Loss: 1457.2640\n",
      "accuracy: 0.972807888656563\n",
      "Epoch: 080, Loss: 1455.8737\n",
      "accuracy: 0.9729291255253936\n",
      "Epoch: 081, Loss: 1460.9735\n",
      "accuracy: 0.9729003650236442\n",
      "Epoch: 082, Loss: 1460.7615\n",
      "accuracy: 0.9728998507470137\n",
      "Epoch: 083, Loss: 1465.7218\n",
      "accuracy: 0.9729172593823777\n",
      "Epoch: 084, Loss: 1457.9810\n",
      "accuracy: 0.9729762100818948\n",
      "Epoch: 085, Loss: 1457.8400\n",
      "accuracy: 0.9729116260507346\n",
      "Epoch: 086, Loss: 1460.0227\n",
      "accuracy: 0.9729615083266377\n",
      "Epoch: 087, Loss: 1465.4302\n",
      "accuracy: 0.9728671147235071\n",
      "Epoch: 088, Loss: 1451.6371\n",
      "accuracy: 0.9730237016034025\n",
      "Epoch: 089, Loss: 1451.7521\n",
      "accuracy: 0.972897550845173\n",
      "Epoch: 090, Loss: 1451.1960\n",
      "accuracy: 0.9729616411689835\n",
      "Epoch: 091, Loss: 1447.1058\n",
      "accuracy: 0.9729309287448706\n",
      "Epoch: 092, Loss: 1454.8805\n",
      "accuracy: 0.9728483069504141\n",
      "Epoch: 093, Loss: 1448.5736\n",
      "accuracy: 0.9726703179401232\n",
      "Epoch: 094, Loss: 1461.8466\n",
      "accuracy: 0.9728986332005471\n",
      "Epoch: 095, Loss: 1471.6774\n",
      "accuracy: 0.9728532298220317\n",
      "Epoch: 096, Loss: 1440.3115\n",
      "accuracy: 0.9727429298854304\n",
      "Epoch: 097, Loss: 1446.1171\n",
      "accuracy: 0.9727880291285881\n",
      "Epoch: 098, Loss: 1454.9454\n",
      "accuracy: 0.9727476499278629\n",
      "Epoch: 099, Loss: 1421.0654\n",
      "accuracy: 0.972911749883993\n",
      "Epoch: 100, Loss: 1440.2263\n",
      "accuracy: 0.9729673040716343\n",
      "Epoch: 101, Loss: 1415.3329\n",
      "accuracy: 0.9728718148336677\n",
      "Epoch: 102, Loss: 1417.1831\n",
      "accuracy: 0.973017876654576\n",
      "Epoch: 103, Loss: 1411.6141\n",
      "accuracy: 0.9729658242504092\n",
      "Epoch: 104, Loss: 1420.7989\n",
      "accuracy: 0.9729357317237557\n",
      "Epoch: 105, Loss: 1416.5345\n",
      "accuracy: 0.9728806960271942\n",
      "Epoch: 106, Loss: 1401.1033\n",
      "accuracy: 0.9729543651684552\n",
      "Epoch: 107, Loss: 1404.5950\n",
      "accuracy: 0.9729385625483685\n",
      "Epoch: 108, Loss: 1401.0854\n",
      "accuracy: 0.9731472286402947\n",
      "Epoch: 109, Loss: 1414.9283\n",
      "accuracy: 0.9730471537574793\n",
      "Epoch: 110, Loss: 1396.8058\n",
      "accuracy: 0.9731240486112844\n",
      "Epoch: 111, Loss: 1401.7750\n",
      "accuracy: 0.9732102308172177\n",
      "Epoch: 112, Loss: 1395.4422\n",
      "accuracy: 0.9731056467665414\n",
      "Epoch: 113, Loss: 1389.7357\n",
      "accuracy: 0.973305719133646\n",
      "Epoch: 114, Loss: 1400.9304\n",
      "accuracy: 0.9731983353127277\n",
      "Epoch: 115, Loss: 1405.0606\n",
      "accuracy: 0.9733876158117675\n",
      "Epoch: 116, Loss: 1402.8257\n",
      "accuracy: 0.9733932359915138\n",
      "Epoch: 117, Loss: 1405.5914\n",
      "accuracy: 0.9735197516197626\n",
      "Epoch: 118, Loss: 1410.9015\n",
      "accuracy: 0.9733294752701476\n",
      "Epoch: 119, Loss: 1408.9652\n",
      "accuracy: 0.9734167864558377\n",
      "Epoch: 120, Loss: 1394.2115\n",
      "accuracy: 0.9733296741679557\n",
      "Epoch: 121, Loss: 1415.6114\n",
      "accuracy: 0.9733497089336888\n",
      "Epoch: 122, Loss: 1395.6317\n",
      "accuracy: 0.9732604041381995\n",
      "Epoch: 123, Loss: 1402.9574\n",
      "accuracy: 0.9732281892593332\n",
      "Epoch: 124, Loss: 1397.8179\n",
      "accuracy: 0.9732237275284822\n",
      "Epoch: 125, Loss: 1400.6369\n",
      "accuracy: 0.9733568918703083\n",
      "Epoch: 126, Loss: 1412.8719\n",
      "accuracy: 0.9732228848025151\n",
      "Epoch: 127, Loss: 1396.1504\n",
      "accuracy: 0.9732188755521174\n",
      "Epoch: 128, Loss: 1416.6239\n",
      "accuracy: 0.973159118812573\n",
      "Epoch: 129, Loss: 1404.1205\n",
      "accuracy: 0.973095871539026\n",
      "Epoch: 130, Loss: 1402.0768\n",
      "accuracy: 0.9730948864316794\n",
      "Epoch: 131, Loss: 1393.1386\n",
      "accuracy: 0.9731801913775289\n",
      "Epoch: 132, Loss: 1387.0930\n",
      "accuracy: 0.9730634857256938\n",
      "Epoch: 133, Loss: 1388.5725\n",
      "accuracy: 0.9732129045135857\n",
      "Epoch: 134, Loss: 1373.1239\n",
      "accuracy: 0.9731213382439541\n",
      "Epoch: 135, Loss: 1362.6834\n",
      "accuracy: 0.9731010209430618\n",
      "Epoch: 136, Loss: 1359.2318\n",
      "accuracy: 0.9730512171625662\n",
      "Epoch: 137, Loss: 1357.8035\n",
      "accuracy: 0.9731924088407164\n",
      "Epoch: 138, Loss: 1365.8138\n",
      "accuracy: 0.9731648856486568\n",
      "Epoch: 139, Loss: 1362.2081\n",
      "accuracy: 0.9731249875232069\n",
      "Epoch: 140, Loss: 1384.2703\n",
      "accuracy: 0.973158950509476\n",
      "Epoch: 141, Loss: 1364.6844\n",
      "accuracy: 0.9730799169693825\n",
      "Epoch: 142, Loss: 1360.7299\n",
      "accuracy: 0.9729628594807113\n",
      "Epoch: 143, Loss: 1357.1973\n",
      "accuracy: 0.9731651891621925\n",
      "Epoch: 144, Loss: 1373.3642\n",
      "accuracy: 0.9731569092497816\n",
      "Epoch: 145, Loss: 1360.8745\n",
      "accuracy: 0.9730903470283208\n",
      "Epoch: 146, Loss: 1361.7419\n",
      "accuracy: 0.9730834497903773\n",
      "Epoch: 147, Loss: 1359.1636\n",
      "accuracy: 0.9729952288742938\n",
      "Epoch: 148, Loss: 1365.5567\n",
      "accuracy: 0.9731292890749084\n",
      "Epoch: 149, Loss: 1364.8404\n",
      "accuracy: 0.9728397279481844\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = AMLtoGraph('data')\n",
    "data = dataset[0]\n",
    "epoch = 150\n",
    "\n",
    "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "data = split(data)\n",
    "\n",
    "train_loader = loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.train_mask,\n",
    ")\n",
    "\n",
    "test_loader = loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.val_mask,\n",
    ")\n",
    "\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "        ground_truth = data.y\n",
    "        loss = criterion(pred, ground_truth.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch: {i:03d}, Loss: {total_loss:.4f}\")\n",
    "        model.eval()\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for test_data in test_loader:\n",
    "            test_data.to(device)\n",
    "            pred = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
    "            ground_truth = test_data.y\n",
    "            correct = (pred == ground_truth.unsqueeze(1)).sum().item()\n",
    "            total += len(ground_truth)\n",
    "            acc += correct\n",
    "        acc = acc/total\n",
    "        print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[195338     54]\n",
      " [  5002      2]]\n",
      "Precision: 0.0357\n",
      "Recall: 0.0004\n",
      "F1 Score: 0.0008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for test_data in test_loader:\n",
    "    test_data.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
    "    predicted_classes = (pred.sigmoid() > 0.5).int()  # Convert probabilities to 0 or 1\n",
    "    all_preds.extend(predicted_classes.cpu().numpy())\n",
    "    all_labels.extend(test_data.y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "# Calculate confusion matrix and other metrics\n",
    "conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GNN_model.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "joblib.dump(model, 'GNN_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'GNN_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
